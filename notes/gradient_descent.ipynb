{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is an algorithm which attempts to repeatedly reduce the error in a hypothesis until it converges on the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Quick reference](#Quick-reference) - quick reference for equations\n",
    "- [Equation](#Equation) - the gradient descent equation\n",
    "- [Vectorized](#Vectorized) - the vectorized equation\n",
    "- [Learning rate](#Learning-rate) - constant that effects the rate of change\n",
    "- [Feature scaling](#Feature-scaling) - scale the features to improve algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick reference\n",
    "\n",
    "Basic equation:\n",
    "\n",
    "$$\n",
    "\\text{repeat simultaneously}:\\quad  \\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\n",
    "$$\n",
    "\n",
    "Vectorized equation (with [linear hypothesis](linear_hypothesis.ipynb)):\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\alpha \\frac{1}{m} ((X\\theta - y)^TX)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation\n",
    "\n",
    "First:\n",
    "\n",
    "1. choose an initial value for your theta values\n",
    "1. choose a good [learning rate](#Learning-rate)\n",
    "1. consider applying [feature scaling](#Feature-scaling)\n",
    "1. calculate the partial derivative of the [cost function](cost_function.ipynb) with your hypothesis (for linear regression it is probably the [linear hypothesis](linear_hypothesis.ipynb))\n",
    "1. subtract the calculated slope of cost times the [learning rate](#Learning-rate) from the previous theta value to get the new theta value\n",
    "\n",
    "Repeat these steps for a set number of repetitions, or until the reduction between runs becomes negligible.\n",
    "\n",
    "[Cost function](cost_function.ipynb): $J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "The equation before calculating the partial derivative:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\n",
    "$$\n",
    "\n",
    "Once you calculate the partial derivative, the equation is:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\n",
    "$$\n",
    "\n",
    "These should be repeated simultaneously! Keep in mind that $x_0$ is assumed to be equal to 1, so for $\\theta_0$ you can remove $x_j^{(i)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized\n",
    "\n",
    "To run gradient descent in a vectorized way you first need to prep a matrix $X$ with a column for each training set. You will also need a vector $y$ with all of the output variables.\n",
    "\n",
    "First, choose your hypothesis. For example, let's use the [linear hypothesis](linear_hypothesis.ipynb):\n",
    "\n",
    "$$\n",
    "X\\theta\n",
    "$$\n",
    "\n",
    "Now fit that into the equation:\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\alpha \\frac{1}{m} ((X\\theta - y)^TX)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate\n",
    "\n",
    "Learning rate helps control the size of each step of gradient descent.\n",
    "\n",
    "When choosing $\\alpha$, try $..., 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, ...$ (3x increases)\n",
    "\n",
    "- $\\alpha$ too small = very slow convergence, non-optimal\n",
    "- $\\alpha$ too large = may not converge (may also have slow convergence due to bouncing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "Feature scaling causes the gradient to be more circular, leading to more direct reductions in error per run of gradient descent.\n",
    "\n",
    "Goal: get every feature to approximately a $-1 \\leq x_i \\leq 1$ range.\n",
    "\n",
    "> Andrew Ng's rule of thumb:\n",
    ">\n",
    "> $-3 \\leq x_i \\leq 3$ is max\n",
    ">\n",
    "> $-\\frac{1}{3} \\leq x_i \\leq \\frac{1}{3}$ is min\n",
    "\n",
    "> See the [meanStandardNormalize](https://github.com/liamross/machine-learning-notes/blob/master/octave_examples/meanStandardNormalize.m) octave equation for a technique where each variable has the mean subtracted, then is divided by the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Octave\n",
    "\n",
    "> View the code for [gradientDescent](https://github.com/liamross/machine-learning-notes/blob/master/octave_examples/gradientDescent.m) with comments here.\n",
    "\n",
    "```octave\n",
    "function [theta, J_history] = gradientDescent (X, y, theta, alpha, num_iters)\n",
    "\n",
    "    m = length(y);\n",
    "    J_history = zeros(num_iters, 1);\n",
    "\n",
    "    for iter = 1:num_iters\n",
    "\n",
    "        hypotheses = X * theta;\n",
    "        theta = theta - alpha * (1 / m) * ((hypotheses - y)' * X)';\n",
    "        J_history(iter) = costFunction(X, y, theta);\n",
    "\n",
    "    end\n",
    "\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From cost_function.ipynb\n",
    "def costFunction(X, y, theta):\n",
    "    m = len(y)\n",
    "    hypothesis = X @ theta\n",
    "    err = hypothesis - y\n",
    "    return ((1 / (2 * m)) * (np.transpose(err) @ err).item((0, 0)))\n",
    "\n",
    "def gradientDescent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros((num_iters, 1))\n",
    "    \n",
    "    for iter in range(0, num_iters):\n",
    "        hypothesis = X @ theta\n",
    "        err = hypothesis - y\n",
    "        theta = theta - alpha * (1 / m) * np.transpose(np.transpose(err) @ X)\n",
    "        J_history[iter, 0] = costFunction(X, y, theta)\n",
    "        \n",
    "    return (theta, J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it against some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final theta_0 (should be ~100): 99.66939172979757\n",
      "Final theta_1 (should be ~40):  40.18972826302451\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 0.8], # 100 + 0.8 * 40 = 132\n",
    "    [1, 2.3], # 100 + 2.3 * 40 = 192\n",
    "    [1, 1.6], # 100 + 1.6 * 40 = 164\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [132],\n",
    "    [192],\n",
    "    [164],\n",
    "])\n",
    "\n",
    "theta = np.array([\n",
    "    [0],\n",
    "    [0],\n",
    "])\n",
    "\n",
    "alpha = 0.5\n",
    "num_iters = 100\n",
    "\n",
    "(theta, history) = gradientDescent(X, y, theta, alpha, num_iters)\n",
    "\n",
    "print(\"Final theta_0 (should be ~100):\", theta.item(0, 0))\n",
    "print(\"Final theta_1 (should be ~40): \", theta.item(1, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
