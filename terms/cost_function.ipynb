{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function\n",
    "\n",
    "The cost function is the most commonly used function for [[regression problem]]. It is designed to find the error between the hypothesis and the provided data.\n",
    "\n",
    "**aka:** \"Squared error function\", or \"Mean squared error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "We could use the [linear hypothesis](linear_hypothesis.ipynb#Equation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "$\\theta_0$ - y intercept at $x = 0$  \n",
    "$\\theta_1$ - slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "The cost function can be defined as:\n",
    "\n",
    "$$\n",
    "J(\\theta_0, \\theta_1) = \\frac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "In the cost function, $h_{\\theta}(x^{(i)})$ is the same as $\\theta_0 + \\theta_1x^{(i)}$ (note this is the same as the hypothesis, and it is effected by changing $\\theta$'s).\n",
    "\n",
    "It is equal to $\\frac{1}{2}\\bar{x}$ where $\\bar{x}$ is the mean of the squares of $h_\\theta(x^{(i)}) - y^{(i)}$. This equals the difference between predicted and actual value. It is halved for convenience of computing [[gradient descent]] (derivative of the square will cancel out the half)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "We want to choose $\\theta_0$ and $\\theta_1$ such that $h_{\\theta}(x)$ is close to $y$ for our training examples $(x, y)$ (minimizing error).\n",
    "\n",
    "$\\substack{minimize\\\\\\theta_0\\theta_1} J(\\theta_0, \\theta_1)$\n",
    "\n",
    "$\\substack{minimize\\\\\\theta_0\\theta_1}$ means \"find me the values of $\\theta_0$ and $\\theta_1$ that minimize the equation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### With zero-value for $\\theta_0$\n",
    "\n",
    "Simplify by setting $\\theta_0 = 0$ (same as removing $\\theta_0$ from the equations).\n",
    "\n",
    "Hypothesis: $h_{\\theta}(x) = \\theta_{1}x$\n",
    "Parameters: $\\theta_1$\n",
    "Cost function: $J(\\theta_1) = \\frac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^{2}$\n",
    "Goal: $\\substack{minimize\\\\\\theta_1} J(\\theta_1)$\n",
    "\n",
    "- for fixed $\\theta_1$, hypothesis $h_\\theta(x)$ is a function of $x$\n",
    "- cost function $J(\\theta_1)$ is a function of $\\theta_1$\n",
    "\n",
    "$$\n",
    "J(1) = \\frac{1}{2\\times3}((1-1)^2 + (2-2)^2 + (3-3)^2) = \\frac{1}{2\\times3}(0 + 0 + 0) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "J(0.5) = \\frac{1}{2\\times3}((0.5-1)^2 + (1-2)^2 + (1.5-3)^2)= \\frac{1}{2\\times3}(0.25 + 1 + 2.25) = \\frac{3.5}{6} \\approx 0.583\n",
    "$$\n",
    "\n",
    "$$\n",
    "J(0) = \\frac{1}{2\\times3}((0-1)^2 + (0-2)^2 + (0-3)^2)= \\frac{1}{2\\times3}(1 + 4 + 9) = \\frac{14}{6} \\approx 0.2.333\n",
    "$$\n",
    "\n",
    "![](../static/cost_function_example.png)\n",
    "\n",
    "From this we can see that the global minimum is at $\\theta_1 = 1$.\n",
    "\n",
    "### With non-zero $\\theta_0$\n",
    "\n",
    "In this example we will not set $\\theta_0$ to equal $0$.\n",
    "\n",
    "Hypothesis: $h_\\theta(x) = \\theta_0 + \\theta_1x$\n",
    "Parameters: $\\theta_0$, $\\theta_1$\n",
    "Cost function: $J(\\theta_0, \\theta_1) = \\frac{1}{2m}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^{2}$\n",
    "Goal: $\\substack{minimize\\\\\\theta_0\\theta_1} J(\\theta_0, \\theta_1)$\n",
    "\n",
    "Since there are two parameters, we need a new way to graph $J(\\theta_0, \\theta_1)$. Rather than use a 3D surface plot, it can be represented in two dimensions using a contour plot.\n",
    "\n",
    "> This will always be a \"convex\" function, in that there will always be a single low point. Local minimum == global minimum.\n",
    "\n",
    "![](../static/3d_surface_vs_contour_plots.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
